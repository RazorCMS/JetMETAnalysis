[CRAB]

jobtype = cmssw
scheduler = condor

[CMSSW]

### The data you want to access (to be found on DBS)
datasetpath = /Jet/Run2011A-May10ReReco-v1/RECO

#######################
#lumi_mask=Cert_132440-147116_7TeV_StreamExpress_Collisions10_JSON.txt
lumi_mask=Cert_160404-163869_7TeV_May10ReReco_Collisions11_JSON.txt
#lumis_per_job = 20
total_number_of_lumis=-1
number_of_jobs = 300
#######################

### The ParameterSet you want to use
pset = treeData_cleaning_cfg.py

[USER]

return_data = 0

### OUTPUT files INTO A SE
copy_data = 1

storage_element  =  srm-cms.cern.ch
storage_path  =  /srm/managerv2?SFN=/castor/cern.ch

##############################
user_remote_dir = /user/a/apresyan/MET/Ntuples/Jet_Run2011A-May10ReReco-v1_2nd
ui_working_dir = crab_07142011_Jet_Run2011A-May10ReReco-v1
##############################

### To publish produced output in a local istance of DBS set publish_data = 1
publish_data=0
### Specify the dataset name. The full path will be <primarydataset>/<publish_data_name>/USER
publish_data_name = name_you_prefer
### Specify the URL of DBS istance where CRAB has to publish the output files
#dbs_url_for_publication = https://cmsdbsprod.cern.ch:8443/cms_dbs_caf_analysis_01_writer/servlet/DBSServlet 


[GRID]

rb = CERN

[CONDORG]
